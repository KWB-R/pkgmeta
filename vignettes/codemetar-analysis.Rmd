---
title: "Codemetar Analysis"
author: "Michael Rustler"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Codemetar Analysis}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Topics

```{r, eval = TRUE}

library(jsonld)
library(jsonlite)
library(magrittr)
library(codemetar)
library(purrr)
library(dplyr)
library(printr)
library(tibble)
##################################################################
### Importing "codemetar.json" 
##################################################################

#"https://kwb-r.github.io/pkgmeta/codemetar.json" %>%  
#  jsonlite::fromJSON() %>% 
#  jsonlite::write_json("codemetar.json")

### Option 2: working as expected

corpus <- jsonlite::fromJSON("codemetar.json",
                             simplifyVector = FALSE)

### add Github topics to R package names
pkg_topics <- tibble::tibble(
       name = purrr::map_chr(corpus, "identifier"),
       topic = purrr::map_chr(
               lapply(purrr::map(corpus, "keywords"), 
                      function(x) {paste(unlist(x), 
                                         collapse = ", ")}),1))
pkg_topics

```

```{r, eval = TRUE}
topics <- tidyr::separate_rows(pkg_topics, topic, sep = ",\\s+") %>% 
  dplyr::count(topic) %>% 
  dplyr::filter(!topic %in% c("r", "rstats")) %>% 
  dplyr::arrange(dplyr::desc(n)) %>% 
  dplyr::rename(word = topic,
                freq = n) 


knitr::kable(topics)


```

```{r wordcloud_topics, eval = TRUE}
wordcloud2::wordcloud2(topics)
```


# Authors

```{r, eval = TRUE}
### Option 1:
### Not working correctly (-> gives list that is twice as long as just
### using jsonlite::fromJSON as defined below

frame <- system.file("schema/frame_schema.json", package="codemetar")

corpus <- jsonld::jsonld_frame("codemetar.json", frame) %>%
 jsonlite::fromJSON("codemetar.json",
                             simplifyVector = FALSE) %>%
  getElement("@graph")


## deal with nulls explicitly by starting with map
pkgs <- purrr::map(corpus, "name") %>%
  purrr::compact() %>%
  as.character()

# keep only those with package identifiers (names)
keep <- purrr::map_lgl(corpus, ~ length(.x$`schema:identifier`) > 0)
corpus <- corpus[keep]

## now we can just do
all_pkgs <- purrr::map_chr(corpus, "name")
head(all_pkgs)

## 3 unique maintainers
purrr::map_chr(corpus, c("maintainer", "familyName")) %>%
  unique() %>%
  length()
```

## Maintainer

```{r, eval = TRUE}
## Mostly Hauke
maintainer <- purrr::map_chr(corpus, c("maintainer", "familyName")) %>%
  tibble::enframe(name = NULL) %>%
  dplyr::group_by(value) %>%
  dplyr::tally(sort=TRUE) %>%
  dplyr::rename(word = value,
                freq = n) 

knitr::kable(maintainer)

```

```{r wordcloud_maintainer, eval = TRUE}
wordcloud2::wordcloud2(maintainer,
                       minSize = 0.4, 
                       size = 0.6)
```


```{r, eval = TRUE}
## number of co-authors ...
purrr::map_int(corpus, function(r) length(r$author)) %>%
  tibble::enframe() %>%
  dplyr::group_by(value) %>%
  dplyr::tally(sort=TRUE) 

## Contributors isn't used as much...
purrr::map_int(corpus, function(r) length(r$contributor)) %>%
  tibble::enframe() %>%
  dplyr::group_by(value) %>%
  dplyr::tally(sort=TRUE)

```

# Package Dependencies


## Depends Imports

```{r, eval = TRUE}
purrr::map_int(corpus, function(r) length(r$softwareRequirements))  %>%
  tibble::enframe() %>%
  dplyr::group_by(value) %>%
  dplyr::tally(sort=TRUE)

corpus %>%
  map_df(function(x){
    ## single, unboxed dep
    if("name" %in% names(x$softwareRequirements))
      dep <- x$`schema:identifier`
    else if("name" %in% names(x$softwareRequirements[[1]]))
      dep <- map_chr(x$softwareRequirements, "name")
    else { ## No requirementsÃŸ
      dep <- NA
    }

    tibble(identifier = x$`schema:identifier`, dep = dep)
  }) %>%
  dplyr::mutate(identifier = gsub("/", "", identifier),
                dep = gsub("/", "", dep)) %>%
  dplyr::filter(!is.na(dep)) -> dep_df


#which dependencies are used most frequently?
dep_count <- dep_df %>%
  dplyr::group_by(dep) %>%
  dplyr::tally(sort = TRUE) %>%
  dplyr::rename(word = dep,
                freq = n)

knitr::kable(dep_count)

```

```{r wordcloud_depends_imports, eval = TRUE}
wordcloud2::wordcloud2(dep_count,
                       minSize = 0.4, 
                       size = 1)
```

## Depends Imports and Suggests

```{r, eval = TRUE}
#Alternate approach using a frame instead of purrr functions for subsetting the
#Note that this gets all Depends and suggests (really all SoftwareApplication
#types mentioned)
dep_frame <- '{
  "@context": "https://raw.githubusercontent.com/codemeta/codemeta/master/codemeta.jsonld",
"@explicit": "true",
"name": {}
}'
dep_sug_count <- jsonld_frame("codemetar.json", dep_frame) %>%
  fromJSON() %>%
  getElement("@graph") %>%
  filter(type == "SoftwareApplication") %>%
  group_by(name) %>%
  tally(sort = TRUE) %>%
  dplyr::rename(word = name,
                freq = n) 

knitr::kable(dep_sug_count)

```

```{r wordcloud_depends_imports_suggests, eval = TRUE}
wordcloud2::wordcloud2(dep_sug_count,
                       minSize = 0.4, 
                       size = 1)
```

# 7 Session Info 

## Plattform

```{r plattform, eval = TRUE, echo= FALSE}
environment <- sessioninfo::session_info()  

knitr::kable(tibble::enframe(unlist(environment$platform)))

```

## Packages

```{r packages, eval = TRUE, echo= FALSE}

print(environment$packages)

```

### Pandoc

```{r pandoc, eval = TRUE, echo= FALSE}

if(rmarkdown::pandoc_available()) {
data.frame(pandoc_directory = rmarkdown::pandoc_exec(),
           pandoc_version = as.character(rmarkdown::pandoc_version()), 
           stringsAsFactors = FALSE)
} else {
  print("No PANDOC installed!")
}

```
